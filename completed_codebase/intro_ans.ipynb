{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1030298",
   "metadata": {},
   "source": [
    "# Step 1: Calling the API :~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "360f3cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here's a fun fact:\n",
      "\n",
      "Singapore is one of only three surviving city-states in the world. The other two are Monaco and Vatican City.\n",
      "\n",
      "Despite its small size, it's a global hub for finance, trade, and transportation, making it a modern-day marvel of urban planning and economic success!\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Call an LLM using OpenRouter + DeepSeek\n",
    "\n",
    "# 1. Ensure dependencies are installed via requirements.txt\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 2. Load API key from .env file\n",
    "# Make sure your .env contains:\n",
    "# OPENROUTER_API_KEY=<yourkey>\n",
    "load_dotenv()\n",
    "\n",
    "# 3. Initialise client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "# 4. Call the free DeepSeek model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat-v3.1:free\",   \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello! Give me a fun fact about Singapore.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. Print the model‚Äôs response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2bbab8",
   "metadata": {},
   "source": [
    "# Step 2: Generating SQL query by passing in db schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64380cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"\"\"{'schema': [{'cid': 0, 'name': 'year', 'type': 'INTEGER'},\n",
    "  {'cid': 1, 'name': 'month_num', 'type': 'INTEGER'},\n",
    "  {'cid': 2, 'name': 'town', 'type': 'VARCHAR'},\n",
    "  {'cid': 3, 'name': 'flat_type', 'type': 'VARCHAR'},\n",
    "  {'cid': 4, 'name': 'block', 'type': 'VARCHAR'},\n",
    "  {'cid': 5, 'name': 'street_name', 'type': 'VARCHAR'},\n",
    "  {'cid': 6, 'name': 'storey_range', 'type': 'VARCHAR'},\n",
    "  {'cid': 7, 'name': 'floor_area_sqm', 'type': 'DOUBLE'},\n",
    "  {'cid': 8, 'name': 'flat_model', 'type': 'VARCHAR'},\n",
    "  {'cid': 9, 'name': 'lease_commence_date', 'type': 'INTEGER'},\n",
    "  {'cid': 10, 'name': 'remaining_lease', 'type': 'VARCHAR'},\n",
    "  {'cid': 11, 'name': 'resale_price', 'type': 'DOUBLE'}],\n",
    " 'categories': {'flat_type': ['1 ROOM',\n",
    "   '2 ROOM',\n",
    "   '3 ROOM',\n",
    "   '4 ROOM',\n",
    "   '5 ROOM',\n",
    "   'EXECUTIVE',\n",
    "   'MULTI-GENERATION'],\n",
    "  'town': ['ANG MO KIO',\n",
    "   'BEDOK',\n",
    "   'BISHAN',\n",
    "   'BUKIT BATOK',\n",
    "   'BUKIT MERAH',\n",
    "   'BUKIT PANJANG',\n",
    "   'BUKIT TIMAH',\n",
    "   'CENTRAL AREA',\n",
    "   'CHOA CHU KANG',\n",
    "   'CLEMENTI',\n",
    "   'GEYLANG',\n",
    "   'HOUGANG',\n",
    "   'JURONG EAST',\n",
    "   'JURONG WEST',\n",
    "   'KALLANG/WHAMPOA',\n",
    "   'MARINE PARADE',\n",
    "   'PASIR RIS',\n",
    "   'PUNGGOL',\n",
    "   'QUEENSTOWN',\n",
    "   'SEMBAWANG',\n",
    "   'SENGKANG',\n",
    "   'SERANGOON',\n",
    "   'TAMPINES',\n",
    "   'TOA PAYOH',\n",
    "   'WOODLANDS',\n",
    "   'YISHUN'],\n",
    "  'flat_model': ['2-room',\n",
    "   '3Gen',\n",
    "   'Adjoined flat',\n",
    "   'Apartment',\n",
    "   'DBSS',\n",
    "   'Improved',\n",
    "   'Improved-Maisonette',\n",
    "   'Maisonette',\n",
    "   'Model A',\n",
    "   'Model A-Maisonette',\n",
    "   'Model A2',\n",
    "   'Multi Generation',\n",
    "   'New Generation',\n",
    "   'Premium Apartment',\n",
    "   'Premium Apartment Loft',\n",
    "   'Premium Maisonette',\n",
    "   'Simplified',\n",
    "   'Standard',\n",
    "   'Terrace',\n",
    "   'Type S1',\n",
    "   'Type S2'],\n",
    "  'storey_range': ['01 TO 03',\n",
    "   '04 TO 06',\n",
    "   '07 TO 09',\n",
    "   '10 TO 12',\n",
    "   '13 TO 15',\n",
    "   '16 TO 18',\n",
    "   '19 TO 21',\n",
    "   '22 TO 24',\n",
    "   '25 TO 27',\n",
    "   '28 TO 30',\n",
    "   '31 TO 33',\n",
    "   '34 TO 36',\n",
    "   '37 TO 39',\n",
    "   '40 TO 42',\n",
    "   '43 TO 45',\n",
    "   '46 TO 48',\n",
    "   '49 TO 51']}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d186418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT year, AVG(resale_price) AS avg_resale_price FROM resale GROUP BY year ORDER BY year;\n"
     ]
    }
   ],
   "source": [
    "def main_agent(user_input: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            f\"\"\"You are an agent that answers questions about HDB resale prices.\n",
    "\n",
    "            This is the schema to the resale db: {schema}\n",
    "\n",
    "            Based on the user's query, generate the required DuckDB query. ONLY REPLY WITH THE QUERY.\n",
    "            \"\"\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-chat-v3.1:free\",\n",
    "        messages=messages,\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    msg = response.choices[0].message.content\n",
    "    \n",
    "    return msg\n",
    "\n",
    "# Interactive mode\n",
    "user_question = input(\"Enter your HDB resale question: \")\n",
    "print(main_agent(user_question))\n",
    "\n",
    "# Example quick test\n",
    "# print(main_agent(\"How has average resale price changed over the years?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683680fb",
   "metadata": {},
   "source": [
    "# Step 3: Tool Time!\n",
    "So far, our LLM could generate SQL text (Step 2).\n",
    "But that‚Äôs not very useful on its own ‚Äî we also want to:\n",
    "* actually run the SQL query on our database, and\n",
    "* then use the results to give insights back to the user.\n",
    "This is where **ü™Ñ tool usage ü™Ñ** comes in!\n",
    "We let the LLM *decide when to call a tool* ‚Äî and we handle the execution in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e921dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the DuckDB database file\n",
    "DB_PATH = \"database/HDB_data.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7f4b1",
   "metadata": {},
   "source": [
    "#### Defining a tool for SQL execution\n",
    "\n",
    "We start by **describing the tool** in a JSON schema.\n",
    "\n",
    "* The tool is named `execute_sql_query`.\n",
    "* It takes one argument: a SQL query string.\n",
    "* The LLM can call this tool whenever it needs to run a query.\n",
    "\n",
    "Think of this like an **extension to the system prompt you give the llm**. It can call this anytime like an **API Call** that we have to resolve for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a75185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool (execute_sql_query) that the LLM can call\n",
    "# Think of this as an addition to your system prompt that the LLM will receive\n",
    "tool = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"execute_sql_query\",\n",
    "            \"description\": \"Execute the DuckDB SQL query and return the results.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"sql_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The DuckDB SQL query to be executed.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"sql_query\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ddb8d",
   "metadata": {},
   "source": [
    "#### Implementing the tool in Python\n",
    "\n",
    "Now when the LLM calls the tool `execute_sql_query` that we give via json schema, we need to resolve that call by doing ~something~ on our end. For this use case, we want to execute the sql query, and we can do that via a Python function with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb3c6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that actually runs the SQL against DuckDB\n",
    "def execute_sql_query(sql_query: str):\n",
    "    if not sql_query:\n",
    "        return {\"error\": \"No SQL query provided\"}\n",
    "    try:\n",
    "        conn = duckdb.connect(DB_PATH)\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_query)\n",
    "        cols = [d[0] for d in c.description] if c.description else []\n",
    "        rows = c.fetchmany(1000)  # cap results for safety\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error executing SQL query: {str(e)}\"}\n",
    "    \n",
    "    return {\"result_df\": {\"columns\": cols, \"rows\": rows}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1bd10",
   "metadata": {},
   "source": [
    "#### Writing the agent loop\n",
    "\n",
    "`main_agent`, ties it all together.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Pass the schema and user query into the model.\n",
    "2. If the user just asks about the schema ‚Üí answer directly.\n",
    "3. Otherwise, the model generates SQL and calls the `execute_sql_query` tool.\n",
    "4. We intercept that tool call, run it in Python, and send the results back.\n",
    "5. Finally, the model produces insights based on the real data.\n",
    "\n",
    "This loop continues until the model stops making tool calls and gives a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a98cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Model wants to call tool: execute_sql_query\n",
      "üìú SQL generated: SELECT year, AVG(resale_price) as average_price FROM resale_data_2017_to_2025 GROUP BY year ORDER BY year;\n",
      "‚úÖ Query executed, got 9 rows\n",
      "üí° Insights from the agent:\n",
      " Based on the data, I can see a clear trend in HDB resale prices over the years:\n",
      "\n",
      "**Key Insights:**\n",
      "- **2017-2019**: Prices remained relatively stable with a slight dip in 2019 (average $432,138)\n",
      "- **2020**: Prices began to recover, reaching $452,279\n",
      "- **2021-2025**: A significant upward trend emerged with consistent year-over-year growth\n",
      "- **2021**: Major jump to $511,381 (13% increase from 2020)\n",
      "- **2022**: Continued growth to $549,714\n",
      "- **2023**: Reached $571,806\n",
      "- **2024**: Surpassed $600,000 mark at $612,600\n",
      "- **2025**: Highest average at $642,113\n",
      "\n",
      "**Overall Trend**: HDB resale prices have increased by approximately **45%** from 2017 to 2025, with the most dramatic growth occurring in the post-2020 period. This suggests strong demand and potentially limited supply in the resale market, along with broader economic factors influencing housing prices in Singapore.\n",
      "\n",
      "=== Insights ===\n",
      " Based on the data, I can see a clear trend in HDB resale prices over the years:\n",
      "\n",
      "**Key Insights:**\n",
      "- **2017-2019**: Prices remained relatively stable with a slight dip in 2019 (average $432,138)\n",
      "- **2020**: Prices began to recover, reaching $452,279\n",
      "- **2021-2025**: A significant upward trend emerged with consistent year-over-year growth\n",
      "- **2021**: Major jump to $511,381 (13% increase from 2020)\n",
      "- **2022**: Continued growth to $549,714\n",
      "- **2023**: Reached $571,806\n",
      "- **2024**: Surpassed $600,000 mark at $612,600\n",
      "- **2025**: Highest average at $642,113\n",
      "\n",
      "**Overall Trend**: HDB resale prices have increased by approximately **45%** from 2017 to 2025, with the most dramatic growth occurring in the post-2020 period. This suggests strong demand and potentially limited supply in the resale market, along with broader economic factors influencing housing prices in Singapore.\n",
      "\n",
      "=== Data Preview ===\n",
      "   year  average_price\n",
      "0  2017  443888.520571\n",
      "1  2018  441282.063703\n",
      "2  2019  432137.912902\n",
      "3  2020  452279.384971\n",
      "4  2021  511381.239001\n"
     ]
    }
   ],
   "source": [
    "# Agent function that coordinates LLM + tool\n",
    "def main_agent(user_input: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            f\"\"\"You are an agent that answers questions about HDB resale prices.\n",
    "\n",
    "            This is the schema to the resale db named `resale_data_2017_to_2025`: {schema}\n",
    "\n",
    "            If the user's query is just about the schema, answer directly.\n",
    "            Otherwise:\n",
    "            1. Generate a SQL query.\n",
    "            2. Call the `execute_sql_query` tool to run it.\n",
    "            3. Give insights based on the query results. REMEMBER TO ALWAYSSS end with insights.\n",
    "            \n",
    "            DO NOT redisplay the raw table in markdown, \n",
    "            it will be shown separately in the app. JUST give the insights.\n",
    "            \"\"\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "\n",
    "    results = None  # to hold SQL results\n",
    "\n",
    "    while True:\n",
    "        # Ask the model what to do\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-chat-v3.1:free\",\n",
    "            messages=messages,\n",
    "            tools=tool,\n",
    "            temperature=0.2\n",
    "        )\n",
    "\n",
    "        msg = response.choices[0].message\n",
    "        messages.append(msg)\n",
    "\n",
    "        # If the model called a tool, run it\n",
    "        if msg.tool_calls:\n",
    "            for call in msg.tool_calls:\n",
    "                print(f\"ü§ñ Model wants to call tool: {call.function.name}\")\n",
    "                args = json.loads(call.function.arguments)\n",
    "\n",
    "                if call.function.name == \"execute_sql_query\":\n",
    "                    sql_query = args.get(\"sql_query\")\n",
    "                    print(f\"üìú SQL generated: {sql_query}\")\n",
    "\n",
    "                    results = execute_sql_query(sql_query)\n",
    "                    if results and \"result_df\" in results:\n",
    "                        print(f\"‚úÖ Query executed, got {len(results['result_df']['rows'])} rows\")\n",
    "                    else:\n",
    "                        print(f\"{results['error']}\")\n",
    "\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": call.id,\n",
    "                        \"content\": json.dumps(results)\n",
    "                    })\n",
    "\n",
    "        else:\n",
    "            # No tool call, so this must be the final answer\n",
    "            print(\"üí° Insights from the agent:\")\n",
    "            print(msg.content)\n",
    "            if not msg.content:\n",
    "                print(\"‚ùå No insights found. Asking agent again\")\n",
    "\n",
    "            if results and \"result_df\" in results:\n",
    "                return {\"insights\": msg.content,\n",
    "                        \"result_df\": results[\"result_df\"]}\n",
    "            else:\n",
    "                return {\"insights\": msg.content,\n",
    "                        \"result_df\": None}\n",
    "            break\n",
    "\n",
    "\n",
    "# Example usage\n",
    "output = main_agent(\"How has average resale price changed over the years?\")\n",
    "\n",
    "# Print results nicely\n",
    "print(\"\\n=== Insights ===\")\n",
    "print(output[\"insights\"])\n",
    "\n",
    "if output[\"result_df\"]:\n",
    "    df = pd.DataFrame(output[\"result_df\"][\"rows\"],\n",
    "                      columns=output[\"result_df\"][\"columns\"])\n",
    "    print(\"\\n=== Data Preview ===\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9df6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
