{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1030298",
   "metadata": {},
   "source": [
    "# Step 1: Calling the API :~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360f3cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here's a fun fact:\n",
      "\n",
      "Singapore is one of only three surviving city-states in the world. The other two are Monaco and Vatican City. This means that the entire country is essentially a single city that functions as a sovereign state, making it a true urban nation!\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Call an LLM using OpenRouter + DeepSeek\n",
    "\n",
    "# 1. Ensure dependencies are installed via requirements.txt\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 2. Load API key from .env file\n",
    "# Make sure your .env contains:\n",
    "# OPENROUTER_API_KEY=<yourkey>\n",
    "load_dotenv()\n",
    "\n",
    "# 3. Initialise client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "# 4. Call the free DeepSeek model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat-v3.1:free\",   \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello! Give me a fun fact about Singapore.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. Print the modelâ€™s response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2bbab8",
   "metadata": {},
   "source": [
    "# Step 2: Generating SQL query by passing in db schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d186418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vars import schema\n",
    "\n",
    "def main_agent(user_input: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            f\"\"\"You are an agent that answers questions about HDB resale prices.\n",
    "\n",
    "            This is the schema to the resale db: {schema}\n",
    "\n",
    "            Based on the user's query, generate the required DuckDB query. ONLY REPLY WITH THE QUERY.\n",
    "            \"\"\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-chat-v3.1:free\",\n",
    "        messages=messages,\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    msg = response.choices[0].message.content\n",
    "    \n",
    "    return msg\n",
    "\n",
    "# Interactive mode\n",
    "user_question = input(\"Enter your HDB resale question: \")\n",
    "print(main_agent(user_question))\n",
    "\n",
    "# Example quick test\n",
    "# print(main_agent(\"How has average resale price changed over the years?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683680fb",
   "metadata": {},
   "source": [
    "# Step 3: Tool Time!\n",
    "So far, our LLM could generate SQL text (Step 2).\n",
    "But thatâ€™s not very useful on its own â€” we also want to:\n",
    "* actually run the SQL query on our database, and\n",
    "* then use the results to give insights back to the user.\n",
    "This is where **ðŸª„ tool usage ðŸª„** comes in!\n",
    "We let the LLM *decide when to call a tool* â€” and we handle the execution in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e921dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from vars import schema\n",
    "\n",
    "# Path to the DuckDB database file\n",
    "DB_PATH = \"database/HDB_data.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7f4b1",
   "metadata": {},
   "source": [
    "#### Defining a tool for SQL execution\n",
    "\n",
    "We start by **describing the tool** in a JSON schema.\n",
    "\n",
    "* The tool is named `execute_sql_query`.\n",
    "* It takes one argument: a SQL query string.\n",
    "* The LLM can call this tool whenever it needs to run a query.\n",
    "\n",
    "Think of this like an **extension to the system prompt you give the llm**. It can call this anytime like an **API Call** that we have to resolve for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a75185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool (execute_sql_query) that the LLM can call\n",
    "# Think of this as an addition to your system prompt that the LLM will receive\n",
    "tool = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"execute_sql_query\",\n",
    "            \"description\": \"Execute the DuckDB SQL query and return the results.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"sql_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The DuckDB SQL query to be executed.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"sql_query\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ddb8d",
   "metadata": {},
   "source": [
    "#### Implementing the tool in Python\n",
    "\n",
    "Now when the LLM calls the tool `execute_sql_query` that we give via json schema, we need to resolve that call by doing ~something~ on our end. For this use case, we want to execute the sql query, and we can do that via a Python function with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that actually runs the SQL against DuckDB\n",
    "def execute_sql_query(sql_query: str):\n",
    "    if not sql_query:\n",
    "        return {\"error\": \"No SQL query provided\"}\n",
    "    try:\n",
    "        conn = duckdb.connect(DB_PATH)\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_query)\n",
    "        cols = [d[0] for d in c.description] if c.description else []\n",
    "        rows = c.fetchmany(1000)  # cap results for safety\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error executing SQL query: {str(e)}\"}\n",
    "    \n",
    "    return {\"result_df\": {\"columns\": cols, \"rows\": rows}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1bd10",
   "metadata": {},
   "source": [
    "#### Writing the agent loop\n",
    "\n",
    "`main_agent`, ties it all together.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Pass the schema and user query into the model.\n",
    "2. If the user just asks about the schema â†’ answer directly.\n",
    "3. Otherwise, the model generates SQL and calls the `execute_sql_query` tool.\n",
    "4. We intercept that tool call, run it in Python, and send the results back.\n",
    "5. Finally, the model produces insights based on the real data.\n",
    "\n",
    "This loop continues until the model stops making tool calls and gives a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a98cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Model wants to call tool: execute_sql_query\n",
      "ðŸ“œ SQL generated: SELECT year, AVG(resale_price) as avg_resale_price FROM resale_data_2017_to_2025 GROUP BY year ORDER BY year\n",
      "âœ… Query executed, got 9 rows\n",
      "ðŸ’¡ Insights from the agent:\n",
      " Based on the data, here's how average HDB resale prices have changed over the years:\n",
      "\n",
      "**Key Insights:**\n",
      "- **2017-2019**: Prices remained relatively stable, with a slight dip in 2019 to around $432,138\n",
      "- **2020**: Prices started recovering, reaching $452,279\n",
      "- **2021-2025**: Significant upward trend with prices increasing substantially each year\n",
      "- **2021**: Major jump to $511,381 (13% increase from 2020)\n",
      "- **2022**: Continued growth to $549,714\n",
      "- **2023**: Further increase to $571,806\n",
      "- **2024**: Reached $612,600\n",
      "- **2025**: Highest average at $642,113\n",
      "\n",
      "**Overall Trend**: The data shows a clear upward trajectory in HDB resale prices, particularly from 2020 onwards. The average price increased by approximately 42% from 2017 ($443,889) to 2025 ($642,113), with the most significant growth occurring in the post-2020 period. This suggests strong demand and potentially limited supply in the HDB resale market in recent years.\n",
      "\n",
      "=== Insights ===\n",
      " Based on the data, here's how average HDB resale prices have changed over the years:\n",
      "\n",
      "**Key Insights:**\n",
      "- **2017-2019**: Prices remained relatively stable, with a slight dip in 2019 to around $432,138\n",
      "- **2020**: Prices started recovering, reaching $452,279\n",
      "- **2021-2025**: Significant upward trend with prices increasing substantially each year\n",
      "- **2021**: Major jump to $511,381 (13% increase from 2020)\n",
      "- **2022**: Continued growth to $549,714\n",
      "- **2023**: Further increase to $571,806\n",
      "- **2024**: Reached $612,600\n",
      "- **2025**: Highest average at $642,113\n",
      "\n",
      "**Overall Trend**: The data shows a clear upward trajectory in HDB resale prices, particularly from 2020 onwards. The average price increased by approximately 42% from 2017 ($443,889) to 2025 ($642,113), with the most significant growth occurring in the post-2020 period. This suggests strong demand and potentially limited supply in the HDB resale market in recent years.\n",
      "\n",
      "=== Data Preview ===\n",
      "   year  avg_resale_price\n",
      "0  2017     443888.520571\n",
      "1  2018     441282.063703\n",
      "2  2019     432137.912902\n",
      "3  2020     452279.384971\n",
      "4  2021     511381.239001\n"
     ]
    }
   ],
   "source": [
    "# Agent function that coordinates LLM + tool\n",
    "def main_agent(user_input: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            f\"\"\"You are an agent that answers questions about HDB resale prices.\n",
    "\n",
    "            This is the schema to the resale db named `resale_data_2017_to_2025`: {schema}\n",
    "\n",
    "            If the user's query is just about the schema, answer directly.\n",
    "            Otherwise:\n",
    "            1. Generate a SQL query.\n",
    "            2. Call the `execute_sql_query` tool to run it.\n",
    "            3. Give insights based on the query results.\n",
    "            \n",
    "            DO NOT redisplay the raw table in markdown, \n",
    "            it will be shown separately in the app. JUST give the insights.\n",
    "            \"\"\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "\n",
    "    results = None  # to hold SQL results\n",
    "\n",
    "    while True:\n",
    "        # Ask the model what to do\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-chat-v3.1:free\",\n",
    "            messages=messages,\n",
    "            tools=tool,\n",
    "            temperature=0.2\n",
    "        )\n",
    "\n",
    "        msg = response.choices[0].message\n",
    "        messages.append(msg)\n",
    "\n",
    "        # If the model called a tool, run it\n",
    "        if msg.tool_calls:\n",
    "            for call in msg.tool_calls:\n",
    "                print(f\"ðŸ¤– Model wants to call tool: {call.function.name}\")\n",
    "                args = json.loads(call.function.arguments)\n",
    "\n",
    "                if call.function.name == \"execute_sql_query\":\n",
    "                    sql_query = args.get(\"sql_query\")\n",
    "                    print(f\"ðŸ“œ SQL generated: {sql_query}\")\n",
    "\n",
    "                    results = execute_sql_query(sql_query)\n",
    "                    print(f\"âœ… Query executed, got {len(results['result_df']['rows'])} rows\")\n",
    "\n",
    "                    # Send results back to the model\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": call.id,\n",
    "                        \"content\": json.dumps(results)\n",
    "                    })\n",
    "\n",
    "        else:\n",
    "            # No tool call, so this must be the final answer\n",
    "            print(\"ðŸ’¡ Insights from the agent:\")\n",
    "            print(msg.content)\n",
    "\n",
    "            if results and \"result_df\" in results:\n",
    "                return {\"insights\": msg.content,\n",
    "                        \"result_df\": results[\"result_df\"]}\n",
    "            else:\n",
    "                return {\"insights\": msg.content,\n",
    "                        \"result_df\": None}\n",
    "            break\n",
    "\n",
    "\n",
    "# Example usage\n",
    "output = main_agent(\"How has average resale price changed over the years?\")\n",
    "\n",
    "# Print results nicely\n",
    "print(\"\\n=== Insights ===\")\n",
    "print(output[\"insights\"])\n",
    "\n",
    "if output[\"result_df\"]:\n",
    "    df = pd.DataFrame(output[\"result_df\"][\"rows\"],\n",
    "                      columns=output[\"result_df\"][\"columns\"])\n",
    "    print(\"\\n=== Data Preview ===\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9df6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
